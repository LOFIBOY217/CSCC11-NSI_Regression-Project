{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7177d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NEIGHBORHOOD-LEVEL SARIMA MODELING\n",
      "================================================================================\n",
      "\n",
      "Original dataset shape: (21910, 10)\n",
      "Date range: 2014-1 to 2025-12\n",
      "Number of neighborhoods: 159\n",
      "\n",
      "Processing 159 neighborhoods...\n",
      "\n",
      "Using SARIMA(0, 1, 1)×(0, 1, 1, 12) for all neighborhoods\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NEIGHBORHOOD-LEVEL SARIMA MODELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/NSI.csv')\n",
    "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
    "\n",
    "# Create datetime column\n",
    "df['date'] = pd.to_datetime({'year': df['REPORT_YEAR'], \n",
    "                              'month': df['REPORT_MONTH'], \n",
    "                              'day': 1})\n",
    "\n",
    "print(f\"Date range: {df['REPORT_YEAR'].min()}-{df['REPORT_MONTH'].min()} to {df['REPORT_YEAR'].max()}-{df['REPORT_MONTH'].max()}\")\n",
    "print(f\"Number of neighborhoods: {df['NEIGHBOURHOOD_158'].nunique()}\")\n",
    "\n",
    "# Get unique neighborhoods\n",
    "neighborhoods = sorted(df['NEIGHBOURHOOD_158'].unique())\n",
    "print(f\"\\nProcessing {len(neighborhoods)} neighborhoods...\")\n",
    "\n",
    "# Storage for results\n",
    "all_results = []\n",
    "neighborhood_summaries = []\n",
    "failed_models = []\n",
    "\n",
    "# SARIMA order (using the best performing simple model from city-wide analysis)\n",
    "order = (0, 1, 1)\n",
    "seasonal_order = (0, 1, 1, 12)\n",
    "\n",
    "print(f\"\\nUsing SARIMA{order}×{seasonal_order} for all neighborhoods\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee1b07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20/159 neighborhoods...\n",
      "Processed 40/159 neighborhoods...\n",
      "Processed 60/159 neighborhoods...\n",
      "Processed 80/159 neighborhoods...\n",
      "Processed 100/159 neighborhoods...\n",
      "Processed 120/159 neighborhoods...\n",
      "Processed 140/159 neighborhoods...\n",
      "\n",
      "✓ Successfully modeled 159 neighborhoods\n",
      "✗ Failed to model 0 neighborhoods\n"
     ]
    }
   ],
   "source": [
    "# Process each neighborhood\n",
    "for idx, neighborhood_id in enumerate(neighborhoods):\n",
    "    try:\n",
    "        # Filter data for this neighborhood\n",
    "        neighborhood_data = df[df['NEIGHBOURHOOD_158'] == neighborhood_id].copy()\n",
    "        neighborhood_data = neighborhood_data.sort_values('date')\n",
    "        neighborhood_data.set_index('date', inplace=True)\n",
    "        \n",
    "        # Get NSI time series\n",
    "        nsi_series = neighborhood_data['NSI']\n",
    "        \n",
    "        # Check if we have enough data\n",
    "        if len(nsi_series) < 50:  # Need at least 50 observations\n",
    "            failed_models.append({\n",
    "                'Neighborhood': neighborhood_id,\n",
    "                'Reason': f'Insufficient data ({len(nsi_series)} observations)'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Train-test split (80-20)\n",
    "        train_size = int(len(nsi_series) * 0.8)\n",
    "        train_data = nsi_series[:train_size]\n",
    "        test_data = nsi_series[train_size:]\n",
    "        \n",
    "        # Skip if test set is too small\n",
    "        if len(test_data) < 5:\n",
    "            failed_models.append({\n",
    "                'Neighborhood': neighborhood_id,\n",
    "                'Reason': f'Test set too small ({len(test_data)} observations)'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Fit SARIMA model\n",
    "        model = SARIMAX(train_data, \n",
    "                       order=order, \n",
    "                       seasonal_order=seasonal_order,\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False)\n",
    "        \n",
    "        fitted_model = model.fit(disp=False, maxiter=200)\n",
    "        \n",
    "        # Make predictions\n",
    "        forecast_steps = len(test_data)\n",
    "        forecast = fitted_model.forecast(steps=forecast_steps)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(test_data, forecast)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(test_data, forecast)\n",
    "        mape = np.mean(np.abs((test_data - forecast) / test_data)) * 100\n",
    "        bias = (test_data - forecast).mean()\n",
    "        \n",
    "        # Store summary for this neighborhood\n",
    "        neighborhood_summaries.append({\n",
    "            'Neighborhood': neighborhood_id,\n",
    "            'Total_Observations': len(nsi_series),\n",
    "            'Train_Size': len(train_data),\n",
    "            'Test_Size': len(test_data),\n",
    "            'Mean_NSI': nsi_series.mean(),\n",
    "            'Std_NSI': nsi_series.std(),\n",
    "            'Min_NSI': nsi_series.min(),\n",
    "            'Max_NSI': nsi_series.max(),\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'Bias': bias,\n",
    "            'AIC': fitted_model.aic,\n",
    "            'BIC': fitted_model.bic\n",
    "        })\n",
    "        \n",
    "        # Store detailed predictions\n",
    "        for date, actual, pred in zip(test_data.index, test_data.values, forecast.values):\n",
    "            all_results.append({\n",
    "                'Neighborhood': neighborhood_id,\n",
    "                'Date': date,\n",
    "                'Actual': actual,\n",
    "                'Predicted': pred,\n",
    "                'Error': actual - pred,\n",
    "                'Abs_Error': abs(actual - pred),\n",
    "                'Pct_Error': abs((actual - pred) / actual) * 100\n",
    "            })\n",
    "        \n",
    "        # Progress update\n",
    "        if (idx + 1) % 20 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(neighborhoods)} neighborhoods...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed_models.append({\n",
    "            'Neighborhood': neighborhood_id,\n",
    "            'Reason': f'Model error: {str(e)[:50]}'\n",
    "        })\n",
    "        continue\n",
    "\n",
    "print(f\"\\nSuccessfully modeled {len(neighborhood_summaries)} neighborhoods\")\n",
    "print(f\"Failed to model {len(failed_models)} neighborhoods\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd018dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OVERALL PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Successfully Modeled Neighborhoods: 159\n",
      "Failed Neighborhoods: 0\n",
      "\n",
      "Total Forecasts Generated: 4450\n",
      "\n",
      "Performance Metrics Across All Neighborhoods:\n",
      "--------------------------------------------------------------------------------\n",
      "Mean MAPE:   10.15% (Std: 44.00%)\n",
      "Median MAPE: 4.85%\n",
      "Best MAPE:   1.88% (Neighborhood 24)\n",
      "Worst MAPE:  520.58% (Neighborhood 90)\n",
      "\n",
      "Mean RMSE:   0.0568\n",
      "Mean MAE:    0.0459\n",
      "Mean Bias:   0.0009\n",
      "\n",
      "NSI Statistics Across Neighborhoods:\n",
      "--------------------------------------------------------------------------------\n",
      "Mean NSI:    0.8547 (Range: 0.4342 - 0.9655)\n",
      "Mean Std:    0.0503\n",
      "\n",
      "Performance Distribution:\n",
      "--------------------------------------------------------------------------------\n",
      "Excellent (MAPE < 5%):     74 neighborhoods (46.5%)\n",
      "Good (MAPE 5-10%):         43 neighborhoods (27.0%)\n",
      "Fair (MAPE 10-20%):        17 neighborhoods (10.7%)\n",
      "Poor (MAPE > 20%):         4 neighborhoods (2.5%)\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrames\n",
    "results_df = pd.DataFrame(all_results)\n",
    "summary_df = pd.DataFrame(neighborhood_summaries)\n",
    "failed_df = pd.DataFrame(failed_models) if failed_models else pd.DataFrame()\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../arima_2/neighborhood_predictions.csv', index=False)\n",
    "summary_df.to_csv('../arima_2/neighborhood_summary.csv', index=False)\n",
    "if len(failed_df) > 0:\n",
    "    failed_df.to_csv('../arima_2/failed_neighborhoods.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Aggregate statistics\n",
    "print(f\"\\nSuccessfully Modeled Neighborhoods: {len(summary_df)}\")\n",
    "print(f\"Failed Neighborhoods: {len(failed_df)}\")\n",
    "print(f\"\\nTotal Forecasts Generated: {len(results_df)}\")\n",
    "\n",
    "print(\"\\nPerformance Metrics Across All Neighborhoods:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Mean MAPE:   {summary_df['MAPE'].mean():.2f}% (Std: {summary_df['MAPE'].std():.2f}%)\")\n",
    "print(f\"Median MAPE: {summary_df['MAPE'].median():.2f}%\")\n",
    "print(f\"Best MAPE:   {summary_df['MAPE'].min():.2f}% (Neighborhood {summary_df.loc[summary_df['MAPE'].idxmin(), 'Neighborhood']})\")\n",
    "print(f\"Worst MAPE:  {summary_df['MAPE'].max():.2f}% (Neighborhood {summary_df.loc[summary_df['MAPE'].idxmax(), 'Neighborhood']})\")\n",
    "\n",
    "print(f\"\\nMean RMSE:   {summary_df['RMSE'].mean():.4f}\")\n",
    "print(f\"Mean MAE:    {summary_df['MAE'].mean():.4f}\")\n",
    "print(f\"Mean Bias:   {summary_df['Bias'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nNSI Statistics Across Neighborhoods:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Mean NSI:    {summary_df['Mean_NSI'].mean():.4f} (Range: {summary_df['Mean_NSI'].min():.4f} - {summary_df['Mean_NSI'].max():.4f})\")\n",
    "print(f\"Mean Std:    {summary_df['Std_NSI'].mean():.4f}\")\n",
    "\n",
    "# Performance categories\n",
    "excellent = len(summary_df[summary_df['MAPE'] < 5])\n",
    "good = len(summary_df[(summary_df['MAPE'] >= 5) & (summary_df['MAPE'] < 10)])\n",
    "fair = len(summary_df[(summary_df['MAPE'] >= 10) & (summary_df['MAPE'] < 20)])\n",
    "poor = len(summary_df[summary_df['MAPE'] >= 20])\n",
    "\n",
    "print(\"\\nPerformance Distribution:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Excellent (MAPE < 5%):     {excellent} neighborhoods ({excellent/len(summary_df)*100:.1f}%)\")\n",
    "print(f\"Good (MAPE 5-10%):         {good} neighborhoods ({good/len(summary_df)*100:.1f}%)\")\n",
    "print(f\"Fair (MAPE 10-20%):        {fair} neighborhoods ({fair/len(summary_df)*100:.1f}%)\")\n",
    "print(f\"Poor (MAPE > 20%):         {poor} neighborhoods ({poor/len(summary_df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7098bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: 01_performance_summary.png\n",
      "✓ Saved: 02_top_bottom_neighborhoods.png\n",
      "✓ Saved: 03_error_analysis.png\n",
      "✓ Saved: neighborhood_analysis_summary.txt\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Generated files:\n",
      "  - neighborhood_predictions.csv (all predictions)\n",
      "  - neighborhood_summary.csv (performance by neighborhood)\n",
      "  - 01_performance_summary.png\n",
      "  - 02_top_bottom_neighborhoods.png\n",
      "  - 03_error_analysis.png\n",
      "  - neighborhood_analysis_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATIONS - STREAMLINED\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Figure 1: Performance distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# MAPE distribution\n",
    "axes[0, 0].hist(summary_df['MAPE'], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(summary_df['MAPE'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {summary_df[\"MAPE\"].mean():.2f}%')\n",
    "axes[0, 0].axvline(summary_df['MAPE'].median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {summary_df[\"MAPE\"].median():.2f}%')\n",
    "axes[0, 0].set_xlabel('MAPE (%)', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Number of Neighborhoods', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_title('Distribution of Forecast Accuracy (MAPE)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# RMSE distribution\n",
    "axes[0, 1].hist(summary_df['RMSE'], bins=30, color='darkgreen', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].axvline(summary_df['RMSE'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {summary_df[\"RMSE\"].mean():.4f}')\n",
    "axes[0, 1].set_xlabel('RMSE', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Number of Neighborhoods', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title('Distribution of RMSE', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# NSI variability vs MAPE\n",
    "axes[1, 0].scatter(summary_df['Std_NSI'], summary_df['MAPE'], alpha=0.6, s=50, color='purple', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('NSI Standard Deviation', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('MAPE (%)', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('NSI Volatility vs Forecast Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Performance categories\n",
    "categories = ['Excellent\\n(<5%)', 'Good\\n(5-10%)', 'Fair\\n(10-20%)', 'Poor\\n(>20%)']\n",
    "counts = [excellent, good, fair, poor]\n",
    "colors_cat = ['green', 'yellowgreen', 'orange', 'red']\n",
    "axes[1, 1].bar(categories, counts, color=colors_cat, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Number of Neighborhoods', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('Performance Category Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (cat, count) in enumerate(zip(categories, counts)):\n",
    "    pct = count/len(summary_df)*100\n",
    "    axes[1, 1].text(i, count, f'{count}\\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima_2/01_performance_summary.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 01_performance_summary.png\")\n",
    "plt.close()\n",
    "\n",
    "# Figure 2: Top 10 and Bottom 10 neighborhoods\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 10 best performing\n",
    "top_10 = summary_df.nsmallest(10, 'MAPE')\n",
    "axes[0].barh(range(len(top_10)), top_10['MAPE'], color='green', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_yticks(range(len(top_10)))\n",
    "axes[0].set_yticklabels([f\"NH {int(n)}\" for n in top_10['Neighborhood']])\n",
    "axes[0].set_xlabel('MAPE (%)', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Top 10 Best Performing Neighborhoods', fontsize=12, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (idx, row) in enumerate(top_10.iterrows()):\n",
    "    axes[0].text(row['MAPE'], i, f\"  {row['MAPE']:.2f}%\", va='center', fontweight='bold')\n",
    "\n",
    "# Bottom 10 worst performing\n",
    "bottom_10 = summary_df.nlargest(10, 'MAPE')\n",
    "axes[1].barh(range(len(bottom_10)), bottom_10['MAPE'], color='red', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_yticks(range(len(bottom_10)))\n",
    "axes[1].set_yticklabels([f\"NH {int(n)}\" for n in bottom_10['Neighborhood']])\n",
    "axes[1].set_xlabel('MAPE (%)', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Top 10 Worst Performing Neighborhoods', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (idx, row) in enumerate(bottom_10.iterrows()):\n",
    "    axes[1].text(row['MAPE'], i, f\"  {row['MAPE']:.2f}%\", va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima_2/02_top_bottom_neighborhoods.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 02_top_bottom_neighborhoods.png\")\n",
    "plt.close()\n",
    "\n",
    "# Figure 3: Overall error analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Overall error distribution\n",
    "axes[0, 0].hist(results_df['Error'], bins=50, color='darkblue', alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 0].axvline(results_df['Error'].mean(), color='orange', linestyle='--', linewidth=2, label=f'Mean: {results_df[\"Error\"].mean():.4f}')\n",
    "axes[0, 0].set_xlabel('Forecast Error', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_title('Overall Error Distribution (All Neighborhoods)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Actual vs Predicted (sample)\n",
    "sample = results_df.sample(min(1000, len(results_df)))\n",
    "axes[0, 1].scatter(sample['Actual'], sample['Predicted'], alpha=0.4, s=20, color='purple')\n",
    "min_val = min(sample['Actual'].min(), sample['Predicted'].min())\n",
    "max_val = max(sample['Actual'].max(), sample['Predicted'].max())\n",
    "axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0, 1].set_xlabel('Actual NSI', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Predicted NSI', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title('Actual vs Predicted (Sample)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# MAPE over time (by date)\n",
    "mape_by_date = results_df.groupby('Date')['Pct_Error'].mean().reset_index()\n",
    "mape_by_date['Date'] = pd.to_datetime(mape_by_date['Date'])\n",
    "axes[1, 0].plot(mape_by_date['Date'], mape_by_date['Pct_Error'], linewidth=2, color='darkorange', marker='o', markersize=4)\n",
    "axes[1, 0].axhline(results_df['Pct_Error'].mean(), color='red', linestyle='--', linewidth=2, label=f'Overall Mean: {results_df[\"Pct_Error\"].mean():.2f}%')\n",
    "axes[1, 0].set_xlabel('Date', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Mean MAPE (%)', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('Forecast Accuracy Over Time', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "plt.setp(axes[1, 0].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Box plot of errors by performance category\n",
    "summary_df['Category'] = pd.cut(summary_df['MAPE'], bins=[0, 5, 10, 20, 100], labels=['Excellent', 'Good', 'Fair', 'Poor'])\n",
    "category_data = []\n",
    "for cat in ['Excellent', 'Good', 'Fair', 'Poor']:\n",
    "    neighborhoods_in_cat = summary_df[summary_df['Category'] == cat]['Neighborhood'].values\n",
    "    errors_in_cat = results_df[results_df['Neighborhood'].isin(neighborhoods_in_cat)]['Error'].values\n",
    "    category_data.append(errors_in_cat)\n",
    "\n",
    "bp = axes[1, 1].boxplot(category_data, labels=['Excellent', 'Good', 'Fair', 'Poor'], patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], ['green', 'yellowgreen', 'orange', 'red']):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[1, 1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1, 1].set_ylabel('Forecast Error', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Performance Category', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('Error Distribution by Performance Category', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima_2/03_error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 03_error_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY REPORT\n",
    "# ============================================================================\n",
    "\n",
    "with open('../arima_2/neighborhood_analysis_summary.txt', 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"NEIGHBORHOOD-LEVEL SARIMA ANALYSIS SUMMARY\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"MODEL CONFIGURATION\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(f\"Model: SARIMA{order}×{seasonal_order}\\n\")\n",
    "    f.write(f\"Total Neighborhoods: {len(neighborhoods)}\\n\")\n",
    "    f.write(f\"Successfully Modeled: {len(summary_df)}\\n\")\n",
    "    f.write(f\"Failed to Model: {len(failed_df)}\\n\")\n",
    "    f.write(f\"Total Forecasts: {len(results_df)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"AGGREGATE PERFORMANCE METRICS\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(f\"Mean MAPE:   {summary_df['MAPE'].mean():.2f}% (Std: {summary_df['MAPE'].std():.2f}%)\\n\")\n",
    "    f.write(f\"Median MAPE: {summary_df['MAPE'].median():.2f}%\\n\")\n",
    "    f.write(f\"Min MAPE:    {summary_df['MAPE'].min():.2f}%\\n\")\n",
    "    f.write(f\"Max MAPE:    {summary_df['MAPE'].max():.2f}%\\n\")\n",
    "    f.write(f\"Mean RMSE:   {summary_df['RMSE'].mean():.4f}\\n\")\n",
    "    f.write(f\"Mean MAE:    {summary_df['MAE'].mean():.4f}\\n\")\n",
    "    f.write(f\"Mean Bias:   {summary_df['Bias'].mean():.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"PERFORMANCE DISTRIBUTION\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(f\"Excellent (MAPE < 5%):     {excellent} ({excellent/len(summary_df)*100:.1f}%)\\n\")\n",
    "    f.write(f\"Good (MAPE 5-10%):         {good} ({good/len(summary_df)*100:.1f}%)\\n\")\n",
    "    f.write(f\"Fair (MAPE 10-20%):        {fair} ({fair/len(summary_df)*100:.1f}%)\\n\")\n",
    "    f.write(f\"Poor (MAPE > 20%):         {poor} ({poor/len(summary_df)*100:.1f}%)\\n\\n\")\n",
    "    \n",
    "    f.write(\"TOP 10 BEST PERFORMING NEIGHBORHOODS\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    for idx, row in top_10.iterrows():\n",
    "        f.write(f\"Neighborhood {int(row['Neighborhood']):3d}: MAPE = {row['MAPE']:6.2f}%, \")\n",
    "        f.write(f\"MAE = {row['MAE']:.4f}, Mean NSI = {row['Mean_NSI']:.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\nTOP 10 WORST PERFORMING NEIGHBORHOODS\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    for idx, row in bottom_10.iterrows():\n",
    "        f.write(f\"Neighborhood {int(row['Neighborhood']):3d}: MAPE = {row['MAPE']:6.2f}%, \")\n",
    "        f.write(f\"MAE = {row['MAE']:.4f}, Mean NSI = {row['Mean_NSI']:.4f}\\n\")\n",
    "    \n",
    "    if len(failed_df) > 0:\n",
    "        f.write(\"\\nFAILED NEIGHBORHOODS\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        for idx, row in failed_df.iterrows():\n",
    "            f.write(f\"Neighborhood {int(row['Neighborhood']):3d}: {row['Reason']}\\n\")\n",
    "\n",
    "print(\"✓ Saved: neighborhood_analysis_summary.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nGenerated files:\")\n",
    "print(\"  - neighborhood_predictions.csv (all predictions)\")\n",
    "print(\"  - neighborhood_summary.csv (performance by neighborhood)\")\n",
    "if len(failed_df) > 0:\n",
    "    print(\"  - failed_neighborhoods.csv (neighborhoods that couldn't be modeled)\")\n",
    "print(\"  - 01_performance_summary.png\")\n",
    "print(\"  - 02_top_bottom_neighborhoods.png\")\n",
    "print(\"  - 03_error_analysis.png\")\n",
    "print(\"  - neighborhood_analysis_summary.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
