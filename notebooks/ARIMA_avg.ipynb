{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b165ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING DATA\n",
      "================================================================================\n",
      "Original dataset shape: (21910, 10)\n",
      "Date range: 2014-1 to 2025-12\n",
      "\n",
      "Aggregated time series shape: (138, 5)\n",
      "Time series range: 2014-04-01 00:00:00 to 2025-09-01 00:00:00\n",
      "Frequency: None\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "              NSI  TotalCrimeScore  Crime_Count  Prev_Month_NSI  NSI_3M_Avg\n",
      "count  138.000000       138.000000   138.000000      138.000000  138.000000\n",
      "mean     0.854593     11218.681159  3229.594203        0.854910    0.855366\n",
      "std      0.020579      1577.159601   519.397667        0.020694    0.019712\n",
      "min      0.804047      7635.000000  2109.000000        0.804047    0.809916\n",
      "25%      0.839856     10194.000000  2857.750000        0.839856    0.841679\n",
      "50%      0.858576     10895.500000  3116.500000        0.858847    0.858340\n",
      "75%      0.867605     12355.750000  3594.500000        0.868112    0.869156\n",
      "max      0.901205     15083.000000  4505.000000        0.901656    0.889467\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Load data\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*80)\n",
    "df = pd.read_csv('../data/NSI.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['REPORT_YEAR'].min()}-{df['REPORT_MONTH'].min()} to {df['REPORT_YEAR'].max()}-{df['REPORT_MONTH'].max()}\")\n",
    "\n",
    "# Create datetime column and aggregate by month\n",
    "df['date'] = pd.to_datetime({'year': df['REPORT_YEAR'], \n",
    "                              'month': df['REPORT_MONTH'], \n",
    "                              'day': 1})\n",
    "\n",
    "# Aggregate by month - NSI is the target (averaged across neighborhoods)\n",
    "# Also include crime metrics as potential context\n",
    "ts_data = df.groupby('date').agg({\n",
    "    'NSI': 'mean',  # TARGET VARIABLE\n",
    "    'TotalCrimeScore': 'sum',\n",
    "    'Crime_Count': 'sum',\n",
    "    'Prev_Month_NSI': 'mean',\n",
    "    'NSI_3M_Avg': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "ts_data.set_index('date', inplace=True)\n",
    "ts_data = ts_data.sort_index()\n",
    "\n",
    "print(f\"\\nAggregated time series shape: {ts_data.shape}\")\n",
    "print(f\"Time series range: {ts_data.index.min()} to {ts_data.index.max()}\")\n",
    "print(f\"Frequency: {ts_data.index.freq}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(ts_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f57282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPLORATORY DATA ANALYSIS\n",
      "================================================================================\n",
      "✓ Saved: 01_time_series_overview.png\n",
      "\n",
      "Performing seasonal decomposition...\n",
      "✓ Saved: 02_seasonal_decomposition.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXPLORATORY DATA ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Plot 1: Time series of NSI (target) and related metrics\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
    "\n",
    "# NSI (Neighborhood Safety Index) - TARGET\n",
    "axes[0].plot(ts_data.index, ts_data['NSI'], linewidth=1.5, color='darkgreen')\n",
    "axes[0].set_title('NSI (Neighborhood Safety Index) Over Time - TARGET VARIABLE', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('NSI', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Total Crime Score (context)\n",
    "axes[1].plot(ts_data.index, ts_data['TotalCrimeScore'], linewidth=1.5, color='darkred')\n",
    "axes[1].set_title('Total Crime Score Over Time (for reference)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Total Crime Score', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Crime Count (context)\n",
    "axes[2].plot(ts_data.index, ts_data['Crime_Count'], linewidth=1.5, color='darkblue')\n",
    "axes[2].set_title('Total Crime Count Over Time (for reference)', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Crime Count', fontsize=12)\n",
    "axes[2].set_xlabel('Date', fontsize=12)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima/01_time_series_overview.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 01_time_series_overview.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Seasonal decomposition\n",
    "print(\"\\nPerforming seasonal decomposition...\")\n",
    "decomposition = seasonal_decompose(ts_data['NSI'], model='additive', period=12)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "decomposition.observed.plot(ax=axes[0], title='Observed', color='darkgreen')\n",
    "decomposition.trend.plot(ax=axes[1], title='Trend', color='darkblue')\n",
    "decomposition.seasonal.plot(ax=axes[2], title='Seasonal', color='darkorange')\n",
    "decomposition.resid.plot(ax=axes[3], title='Residual', color='darkred')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylabel('Value')\n",
    "    \n",
    "axes[3].set_xlabel('Date')\n",
    "fig.suptitle('Seasonal Decomposition of NSI (Neighborhood Safety Index)', fontsize=16, fontweight='bold', y=1.001)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima/02_seasonal_decomposition.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 02_seasonal_decomposition.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07f584ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATIONARITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Original Series (NSI)\n",
      "ADF Statistic: -2.097649\n",
      "p-value: 0.245461\n",
      "Critical Values:\n",
      "   1%: -3.485\n",
      "   5%: -2.885\n",
      "   10%: -2.579\n",
      "→ Series is NON-STATIONARY (fail to reject H0)\n",
      "\n",
      "First Difference\n",
      "ADF Statistic: -2.255635\n",
      "p-value: 0.186676\n",
      "Critical Values:\n",
      "   1%: -3.485\n",
      "   5%: -2.885\n",
      "   10%: -2.579\n",
      "→ Series is NON-STATIONARY (fail to reject H0)\n",
      "\n",
      "Seasonal Difference (lag=12)\n",
      "ADF Statistic: -2.493161\n",
      "p-value: 0.117147\n",
      "Critical Values:\n",
      "   1%: -3.490\n",
      "   5%: -2.887\n",
      "   10%: -2.581\n",
      "→ Series is NON-STATIONARY (fail to reject H0)\n",
      "\n",
      "✓ Saved: 03_acf_pacf_plots.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STATIONARITY TESTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATIONARITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def adf_test(series, name=''):\n",
    "    \"\"\"Perform Augmented Dickey-Fuller test\"\"\"\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'\\n{name}')\n",
    "    print(f'ADF Statistic: {result[0]:.6f}')\n",
    "    print(f'p-value: {result[1]:.6f}')\n",
    "    print(f'Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'   {key}: {value:.3f}')\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"→ Series is STATIONARY (reject H0)\")\n",
    "    else:\n",
    "        print(\"→ Series is NON-STATIONARY (fail to reject H0)\")\n",
    "    return result[1]\n",
    "\n",
    "# Test original series\n",
    "p_value_original = adf_test(ts_data['NSI'], 'Original Series (NSI)')\n",
    "\n",
    "# Test first difference\n",
    "ts_data['NSI_diff1'] = ts_data['NSI'].diff()\n",
    "p_value_diff1 = adf_test(ts_data['NSI_diff1'], 'First Difference')\n",
    "\n",
    "# Test seasonal difference\n",
    "ts_data['NSI_seasonal_diff'] = ts_data['NSI'].diff(12)\n",
    "p_value_seasonal = adf_test(ts_data['NSI_seasonal_diff'], 'Seasonal Difference (lag=12)')\n",
    "\n",
    "# Plot ACF and PACF\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Original series\n",
    "plot_acf(ts_data['NSI'].dropna(), lags=40, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('ACF: Original Series (NSI)', fontsize=12, fontweight='bold')\n",
    "plot_pacf(ts_data['NSI'].dropna(), lags=40, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('PACF: Original Series (NSI)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# First differenced series\n",
    "plot_acf(ts_data['NSI_diff1'].dropna(), lags=40, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('ACF: First Difference', fontsize=12, fontweight='bold')\n",
    "plot_pacf(ts_data['NSI_diff1'].dropna(), lags=40, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('PACF: First Difference', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima/03_acf_pacf_plots.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n✓ Saved: 03_acf_pacf_plots.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b831580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAIN-TEST SPLIT\n",
      "================================================================================\n",
      "Training set: 2014-04-01 00:00:00 to 2023-05-01 00:00:00 (110 observations)\n",
      "Test set: 2023-06-01 00:00:00 to 2025-09-01 00:00:00 (28 observations)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use 80% for training, 20% for testing\n",
    "train_size = int(len(ts_data) * 0.8)\n",
    "train_data = ts_data['NSI'][:train_size]\n",
    "test_data = ts_data['NSI'][train_size:]\n",
    "\n",
    "print(f\"Training set: {train_data.index.min()} to {train_data.index.max()} ({len(train_data)} observations)\")\n",
    "print(f\"Test set: {test_data.index.min()} to {test_data.index.max()} ({len(test_data)} observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd7d3d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SARIMA MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      "Testing different SARIMA configurations...\n",
      "--------------------------------------------------------------------------------\n",
      "SARIMA(1, 1, 1)x(1, 1, 1, 12): AIC=-526.23, BIC=-514.14\n",
      "SARIMA(2, 1, 2)x(1, 1, 1, 12): AIC=-520.17, BIC=-503.33\n",
      "SARIMA(1, 1, 2)x(1, 1, 1, 12): AIC=-519.11, BIC=-504.66\n",
      "SARIMA(0, 1, 1)x(0, 1, 1, 12): AIC=-527.59, BIC=-520.33\n",
      "SARIMA(1, 1, 0)x(1, 1, 0, 12): AIC=-519.41, BIC=-512.12\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Best Model: SARIMA(0, 1, 1)x(0, 1, 1, 12)\n",
      "AIC: -527.59\n",
      "\n",
      "Model Summary:\n",
      "                                     SARIMAX Results                                      \n",
      "==========================================================================================\n",
      "Dep. Variable:                                NSI   No. Observations:                  110\n",
      "Model:             SARIMAX(0, 1, 1)x(0, 1, 1, 12)   Log Likelihood                 266.793\n",
      "Date:                            Mon, 01 Dec 2025   AIC                           -527.587\n",
      "Time:                                    15:22:48   BIC                           -520.330\n",
      "Sample:                                04-01-2014   HQIC                          -524.671\n",
      "                                     - 05-01-2023                                         \n",
      "Covariance Type:                              opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ma.L1         -0.1110      0.101     -1.100      0.271      -0.309       0.087\n",
      "ma.S.L12      -0.8990      0.288     -3.120      0.002      -1.464      -0.334\n",
      "sigma2      8.322e-05   1.75e-05      4.766      0.000     4.9e-05       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.01   Jarque-Bera (JB):                48.02\n",
      "Prob(Q):                              0.92   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.39   Skew:                             0.90\n",
      "Prob(H) (two-sided):                  0.39   Kurtosis:                         6.26\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SARIMA MODEL FITTING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SARIMA MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define SARIMA parameters to test\n",
    "# Based on ACF/PACF analysis and seasonal pattern (period=12)\n",
    "# We'll test a few configurations\n",
    "\n",
    "sarima_configs = [\n",
    "    ((1, 1, 1), (1, 1, 1, 12)),  # Classic SARIMA\n",
    "    ((2, 1, 2), (1, 1, 1, 12)),  # Higher order\n",
    "    ((1, 1, 2), (1, 1, 1, 12)),  # Alternative\n",
    "    ((0, 1, 1), (0, 1, 1, 12)),  # Simple model\n",
    "    ((1, 1, 0), (1, 1, 0, 12)),  # AR only\n",
    "]\n",
    "\n",
    "best_aic = np.inf\n",
    "best_model = None\n",
    "best_order = None\n",
    "results_list = []\n",
    "\n",
    "print(\"\\nTesting different SARIMA configurations...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for order, seasonal_order in sarima_configs:\n",
    "    try:\n",
    "        model = SARIMAX(train_data, \n",
    "                       order=order, \n",
    "                       seasonal_order=seasonal_order,\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False)\n",
    "        fitted_model = model.fit(disp=False, maxiter=200)\n",
    "        \n",
    "        aic = fitted_model.aic\n",
    "        bic = fitted_model.bic\n",
    "        \n",
    "        results_list.append({\n",
    "            'Order': order,\n",
    "            'Seasonal_Order': seasonal_order,\n",
    "            'AIC': aic,\n",
    "            'BIC': bic\n",
    "        })\n",
    "        \n",
    "        print(f\"SARIMA{order}x{seasonal_order}: AIC={aic:.2f}, BIC={bic:.2f}\")\n",
    "        \n",
    "        if aic < best_aic:\n",
    "            best_aic = aic\n",
    "            best_model = fitted_model\n",
    "            best_order = (order, seasonal_order)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"SARIMA{order}x{seasonal_order}: Failed - {str(e)[:50]}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nBest Model: SARIMA{best_order[0]}x{best_order[1]}\")\n",
    "print(f\"AIC: {best_aic:.2f}\")\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(best_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b98bfc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL DIAGNOSTICS\n",
      "================================================================================\n",
      "✓ Saved: 04_model_diagnostics.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODEL DIAGNOSTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Plot diagnostics\n",
    "fig = best_model.plot_diagnostics(figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima/04_model_diagnostics.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 04_model_diagnostics.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10e25e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL PREDICTIONS AND EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Test Set Performance Metrics:\n",
      "==================================================\n",
      "RMSE:  0.03\n",
      "MAE:   0.02\n",
      "MAPE:  2.56%\n",
      "R²:    -3.4735\n",
      "\n",
      "Training Set Performance Metrics:\n",
      "==================================================\n",
      "RMSE:  0.10\n",
      "MAE:   0.02\n",
      "R²:    -40.5285\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PREDICTIONS AND EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PREDICTIONS AND EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# In-sample predictions (training set)\n",
    "train_predictions = best_model.fittedvalues\n",
    "\n",
    "# Out-of-sample predictions (test set)\n",
    "forecast_steps = len(test_data)\n",
    "forecast = best_model.forecast(steps=forecast_steps)\n",
    "forecast_index = test_data.index\n",
    "\n",
    "# Calculate metrics for test set\n",
    "mse = mean_squared_error(test_data, forecast)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_data, forecast)\n",
    "mape = np.mean(np.abs((test_data - forecast) / test_data)) * 100\n",
    "r2 = r2_score(test_data, forecast)\n",
    "\n",
    "print(f\"\\nTest Set Performance Metrics:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"RMSE:  {rmse:.2f}\")\n",
    "print(f\"MAE:   {mae:.2f}\")\n",
    "print(f\"MAPE:  {mape:.2f}%\")\n",
    "print(f\"R²:    {r2:.4f}\")\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_mse = mean_squared_error(train_data, train_predictions)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_mae = mean_absolute_error(train_data, train_predictions)\n",
    "train_r2 = r2_score(train_data, train_predictions)\n",
    "\n",
    "print(f\"\\nTraining Set Performance Metrics:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"RMSE:  {train_rmse:.2f}\")\n",
    "print(f\"MAE:   {train_mae:.2f}\")\n",
    "print(f\"R²:    {train_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "684c664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: 05_actual_vs_predicted.png\n",
      "✓ Saved: 06_test_set_detail.png\n",
      "✓ Saved: 07_residual_analysis.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION OF RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Plot 1: Actual vs Predicted (Full Series)\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "# Plot training data\n",
    "ax.plot(train_data.index, train_data.values, \n",
    "        label='Training Data', color='blue', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Plot test data\n",
    "ax.plot(test_data.index, test_data.values, \n",
    "        label='Test Data', color='green', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Plot predictions on training set\n",
    "ax.plot(train_data.index, train_predictions, \n",
    "        label='Training Predictions', color='orange', linewidth=1.5, alpha=0.8, linestyle='--')\n",
    "\n",
    "# Plot forecast on test set\n",
    "ax.plot(forecast_index, forecast, \n",
    "        label='Test Forecast', color='red', linewidth=2, alpha=0.9)\n",
    "\n",
    "# Add confidence interval for forecast\n",
    "forecast_df = best_model.get_forecast(steps=forecast_steps)\n",
    "forecast_ci = forecast_df.conf_int()\n",
    "ax.fill_between(forecast_index, \n",
    "                forecast_ci.iloc[:, 0], \n",
    "                forecast_ci.iloc[:, 1], \n",
    "                color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "\n",
    "ax.set_title(f'SARIMA{best_order[0]}x{best_order[1]}: Actual vs Predicted NSI', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('NSI (Neighborhood Safety Index)', fontsize=12)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima/05_actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 05_actual_vs_predicted.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Zoomed in on Test Period\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(test_data.index, test_data.values, \n",
    "        label='Actual', color='green', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(forecast_index, forecast, \n",
    "        label='Forecast', color='red', linewidth=2, marker='s', markersize=4)\n",
    "\n",
    "ax.fill_between(forecast_index, \n",
    "                forecast_ci.iloc[:, 0], \n",
    "                forecast_ci.iloc[:, 1], \n",
    "                color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "\n",
    "ax.set_title('Test Set: Actual vs Forecast NSI (Detailed View)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('NSI (Neighborhood Safety Index)', fontsize=12)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima/06_test_set_detail.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 06_test_set_detail.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Residuals Analysis\n",
    "residuals = test_data.values - forecast\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Residuals over time\n",
    "axes[0, 0].plot(forecast_index, residuals, color='darkred', linewidth=1.5)\n",
    "axes[0, 0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[0, 0].set_title('Residuals Over Time', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Residual')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of residuals\n",
    "axes[0, 1].hist(residuals, bins=15, color='darkblue', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Distribution of Residuals', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Residual')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter: Actual vs Predicted\n",
    "axes[1, 1].scatter(test_data.values, forecast, alpha=0.6, color='purple', s=50)\n",
    "axes[1, 1].plot([test_data.min(), test_data.max()], \n",
    "                [test_data.min(), test_data.max()], \n",
    "                'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1, 1].set_title('Actual vs Predicted', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Actual')\n",
    "axes[1, 1].set_ylabel('Predicted')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../arima/07_residual_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: 07_residual_analysis.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ce9dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      "✓ Saved: sarima_predictions.csv\n",
      "✓ Saved: model_comparison.csv\n",
      "✓ Saved: sarima_summary.txt\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "All outputs saved to: ../arima/\n",
      "\n",
      "Generated files:\n",
      "  - 01_time_series_overview.png\n",
      "  - 02_seasonal_decomposition.png\n",
      "  - 03_acf_pacf_plots.png\n",
      "  - 04_model_diagnostics.png\n",
      "  - 05_actual_vs_predicted.png\n",
      "  - 06_test_set_detail.png\n",
      "  - 07_residual_analysis.png\n",
      "  - sarima_predictions.csv\n",
      "  - model_comparison.csv\n",
      "  - sarima_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_data.index,\n",
    "    'Actual': test_data.values,\n",
    "    'Predicted': forecast.values,\n",
    "    'Residual': residuals,\n",
    "    'Lower_CI': forecast_ci.iloc[:, 0].values,\n",
    "    'Upper_CI': forecast_ci.iloc[:, 1].values\n",
    "})\n",
    "\n",
    "results_df.to_csv('../arima/sarima_predictions.csv', index=False)\n",
    "print(\"✓ Saved: sarima_predictions.csv\")\n",
    "\n",
    "# Save model comparison results\n",
    "comparison_df = pd.DataFrame(results_list)\n",
    "comparison_df = comparison_df.sort_values('AIC')\n",
    "comparison_df.to_csv('../arima/model_comparison.csv', index=False)\n",
    "print(\"✓ Saved: model_comparison.csv\")\n",
    "\n",
    "# Create summary report\n",
    "with open('../arima/sarima_summary.txt', 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"SARIMA MODEL SUMMARY REPORT\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"DATA INFORMATION\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(f\"Total observations: {len(ts_data)}\\n\")\n",
    "    f.write(f\"Training set: {len(train_data)} observations ({train_data.index.min()} to {train_data.index.max()})\\n\")\n",
    "    f.write(f\"Test set: {len(test_data)} observations ({test_data.index.min()} to {test_data.index.max()})\\n\\n\")\n",
    "    \n",
    "    f.write(\"BEST MODEL\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(f\"Model: SARIMA{best_order[0]}x{best_order[1]}\\n\")\n",
    "    f.write(f\"AIC: {best_aic:.2f}\\n\")\n",
    "    f.write(f\"BIC: {best_model.bic:.2f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"PERFORMANCE METRICS - TEST SET\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(f\"RMSE:  {rmse:.2f}\\n\")\n",
    "    f.write(f\"MAE:   {mae:.2f}\\n\")\n",
    "    f.write(f\"MAPE:  {mape:.2f}%\\n\")\n",
    "    f.write(f\"R²:    {r2:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"PERFORMANCE METRICS - TRAINING SET\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(f\"RMSE:  {train_rmse:.2f}\\n\")\n",
    "    f.write(f\"MAE:   {train_mae:.2f}\\n\")\n",
    "    f.write(f\"R²:    {train_r2:.4f}\\n\\n\")\n",
    "\n",
    "print(\"✓ Saved: sarima_summary.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAll outputs saved to: ../arima/\")\n",
    "print(f\"\\nGenerated files:\")\n",
    "print(\"  - 01_time_series_overview.png\")\n",
    "print(\"  - 02_seasonal_decomposition.png\")\n",
    "print(\"  - 03_acf_pacf_plots.png\")\n",
    "print(\"  - 04_model_diagnostics.png\")\n",
    "print(\"  - 05_actual_vs_predicted.png\")\n",
    "print(\"  - 06_test_set_detail.png\")\n",
    "print(\"  - 07_residual_analysis.png\")\n",
    "print(\"  - sarima_predictions.csv\")\n",
    "print(\"  - model_comparison.csv\")\n",
    "print(\"  - sarima_summary.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
